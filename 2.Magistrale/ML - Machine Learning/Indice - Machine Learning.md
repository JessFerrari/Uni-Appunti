---
Percorso: "[[Indice - Magistrale AI|Magistrale AI]]"
tags:
  - "#indice"
  - ML
  - AI
---
# Machine Learning

# Indice
---
1. [[Machine learning|Machine learning in general]]
	1. [[Machine learning - Data and concept representation]]
	2. [[Machine Learning Model]]
		1. [[Parametric Machine Learning Models]]
		2. [[Instance Based Machine Learning Models]]
	3. [[Machine learning - Task]]
	4. [[Machine Learning Algorithms]]
		1. [[Supervised Learning]]
			1. [[Classification]]
			2. [[Regression]]
		2. [[Unsupervised Learning]]
		3. [[Semi-supervised Learning]]
		4. [[Reinforcement Learning]]
	5. [[Inductive Bias]]
		1. [[Version space]]
		2. [[Unbiased learner theorem]]
		3. [[Search and Language Bias]]
	6. [[Loss Function]]
	7. [[Machine learning#Loss|Loss]]
	8. [[Generalization]]
	9. [[Overfitting and Underfitting]]
2. [[Linear models]]
	1. [[Linear models - regression]]
	2. [[Linear models - classification - LTU]]	 
		1. [[LTU - Linear Threshold Unit]]
	3. [[Learning algorithms]]
	4. [[Linear Basis Expansion - LBE]]
	5. [[Regularization]]
	6. [[Multi Class Task]]
		1. [[K-nn]]
		2.  [[Curse of dimensionality]]
3. [[Neural Networks]]
	1. [[Perceptron]]
		1. [[Perceptron convergence Theorem]]
	2. [[Feed Forward]]
	3. [[Activation functions]]
		1. [[Activation functions - Sigmoidal-Logistic Function]]
		2. [[Activation functions - TanH]]
		3. [[Activation function - ReLu]]
		4. [[Activation functions - Leaky ReLu]]
		5. [[Activation functions - Radial Basis Function]]
	4. [[Universal approximation theorem]]
	5. [[Gradient descent algorithm]]
	6. [[Back Propagation]]
		1. [[Regularization]]
		2. [[Optimization Algorithms#Momentum|Momentum]]
	7. [[ADAM]]
	8. [[Neural Networks - architecture strategies]]
	9. [[Issues in training]]
	10. [[Vanishing gradient]]
	11. [[Exploding gradient]]
	12. [[Cascade Correlation (CC)]]
	13. [[Neural Networks - Autoencoder]]
	14. [[Neural Networks - Autoassociator]] 
4. [[Model selection e Model assessment]]
5. [[Statistical Learning Theory - Vapnik|SLT]]
	1. [[VC-Dimension]]
6. [[SVM]]
	1. [[SVM - Quadratic Optimization Problem]]
	2. [[SVM - Kernel]]
	3. [[Cover's Theorem - Separability of patterns]]
	4. [[SVM for linear regression]]
7. [[Bias-Variance]]
8. [[Ensemble]]
9. [[Deep Learning]]
	1. [[Transfer Learning]]
	2. [[Drop Out]]
10. [[Convolutional Neural Networks (CNN)]]
	1. [[AlexNet]]
11. [[Random weights NN]]
12. [[Self Organizing Map (SOM)]]
13. [[K-means]]
14. [[Recurrent Neural Networks (RNN)]]
15. [[Deep Graph Networks]]



## TODO

| Slides | Appunti                          | Argomenti           | 1 Rep                                        | 2 Rep | 3 Rep |
| :----- | :------------------------------- | :------------------ | :------------------------------------------- | :---- | :---- |
| 1      | ok                               | ML in general       | - loss x clustering and density distribution |       |       |
| 2      | ok                               | Linear models       |                                              |       |       |
| 3      | ok                               | Neural Networks     |                                              |       |       |
| 4      | ok                               | Learning Algorithms |                                              |       |       |
| 5      | LBE                              | CC                  |                                              |       |       |
| 6      | finire appunti                   | Validation          |                                              |       |       |
| 7      | scriverli                        | SLT                 |                                              |       |       |
| 8      | scriverli<br>- Esercizio CC (65) | SVM                 |                                              |       |       |
| 9      | ok                               | Bias-Variance       |                                              |       |       |
| 10     | ok                               | Ensembles           |                                              |       |       |
| 11     | Da scrivere è noiso              | CNN                 |                                              |       |       |
| 12     | esercizio slide 13               | DeepLearning        |                                              |       |       |
| 13     | ok                               | Random Weight NN    |                                              |       |       |
| 14     |                                  | SOM                 |                                              |       |       |
| 15     |                                  | RNN                 |                                              |       |       |
| 16     |                                  | Deep Graph Network  |                                              |       |       |
| 17     |                                  |                     |                                              |       |       |
| 18     |                                  |                     |                                              |       |       |
| 19     |                                  |                     |                                              |       |       |
| 20     |                                  |                     |                                              |       |       |
| 21     |                                  |                     |                                              |       |       |


#### Da sistemare
- [ ] 4 : 32-38
- [ ] 5 : 32-33
- [ ] 5 : 47
- [ ] 8 : 65 -> esercizio CC (in più devo finire di scrivere)
- [ ] 11 : non ho scritto perché mi annoiavo
- [ ] 12 : 15 - 22