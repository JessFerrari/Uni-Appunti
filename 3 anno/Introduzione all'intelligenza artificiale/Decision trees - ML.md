Usare gli alberi di decisione permettono di avere un approccio pratico nella creazione della funzione.

In un DT sono presenti attributi con vincoli che permettono di arrivare ad una risposta finale. si parte da una radice e attraverso il path si arriva alla soluzione che si trova nelle foglie (nelle foglie si trova la classificazione).

Il Machine Learning si occupa di costruire tale albero partendo da un training set.

Un albero di decisione si può esprimere con la logica proposizionale come disgiunzioni di congiunzioni di vincoli sugli attributi (if then else).

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c9807e7e-d210-4154-a029-985d61a23d1b/Untitled.png)

Lo spazio delle ipotesi è espressivo in quanto è capace di poter rappresentare qualsiasi insieme finito di funzioni discrete proposizionali.

## Algoritmo induttivo per alberi decisione ID£

ID3 è un algoritmo di base per fare ML sui DT.

Dato un training set di esempi, l’algoritmo costruisce l’albero di decisione cercando nello spazio delle ipotesi.

La costruzione dell’albero avviene in maniera TOP-DOWN facendo una greedy search, si parte dalla radice e man mano si creano nodi.

Per selezionare il nodo successivo si fa la ricerca greedy per trovare quell’attributo che dia maggiori informazioni.

1. si seleziona il miglior attributo
2. viene creato un nodo discendente per ciascun valore dell’attributo
3. gli esempi vengono classificati in base a questo attributo.
4. si ripete fino a quando tutti gli esempi sono classificati o fino a quando non rimangono più attributi da classificare

```jsx
ID3(X, T, Attrs) {
	X: training examples 
	T: target attribute (e.g. PlayTennis), 
	Attrs: other attributes, initially all attributes

	Create Root node
	If all X's are +, return Root with class +
	If all X's are –, return Root with class –
	If Attrs is empty return Root with class most common value of T in X
	else
	A = best attribute; decision attribute for Root = A

	For each possible value vi of A:
		add a new branch below Root, for test A = vi
		Xi = subset of X with A = vi
		If Xi is empty then add a new leaf with class the most common value of T in X
		else add the subtree generated by ID3(Xi, T, Attrs − {A})

return Root}
```

Per scegliere il miglior attributo va introdotto il concetto di ENTROPIA. L’entropia misura l’impurità di una collezione di esempi e dipende dalla distribuzione di una variabile random p.

DEF:

Sia S una collezione di esempi di training e $p_-$ la porzione degli esempi negativi in S e $p_+$ la porzione degli esempi positivi in S.

[nota che p- e p+ sono frazioni di S]

L’entropia di s è:

$$ Entropy(S)=-p_{+}\log_2p_{+}-p_-\log_2p_- $$

Esempi:

$Entropy([14_+,0_-])=-\frac{14}{14}\log_2\frac{14}{14}-0\log_2(0)=0$

> Dato un’insieme con 14 esempi di cui sono tutti positivi si ha che l’entropia è 0

$Entropy([9_+,5_-])=-\frac9{14}\log_2\frac9{14}-\frac5{14}\log_2\frac5{14}=0.94$

> Se gli esempi sono misti si ha un’entropia che può essere alta o bassa, compresa tra 0 e 1

$Entropy([7_+,7_-])=-\frac 7 {14}\log_2\frac 7{14}-\frac 7{14}\log_2\frac7{14}=1$

> In questo caso non si ha omogeneità e quindi l’entropia è molto alta

nota : $0\log_20=0, \ \ \ \log_2\frac1 2=-1$

Se l’entropia è altra non si hanno abbastanza informazioni e non si può decidere nulla.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/202a1d9e-2583-4bad-b30b-6137d1258788/Untitled.png)

La selezione dell’attributo si fa secondo la regola dell’ INFORMATION GAIN, ossia la riduzione aspettata dell’entropia causata dal ripartire gli esempi in base all’attributo.

Dato che si deve scegliere un’attributo si proveranno vari attributi e di questi si calcola l’information gain, ossia quanto tale attributo ridurrebbe il valore dell’entropia.

$$ Gain(S,A)=Entropy(S)-\sum_{v\in Values(A)}\frac {|Sv|}{|S|}Entropy(Sv) $$

- Values(A) = possibili valori dell’attributo A
- Sv = sottoinsieme di esempi di S per ogni attributo che ha valore v

Più è alta l’information gain più l’attributo avrà effetto nel classificare i dati di training.

Una classificazione netta si ha quando si hanno dati omogenei, ad esempio [14+,0-] o [0+,14-].

Se la seconda parte si abbassa allora il gain aumenta.

Potrebbe capitare che l’information gain favorisca attributi con numerosi valori. Ad esempio se per la scelta di andare a giocare a tennis non è significante la data sulla scelta, ma se si inserisce tale attributo fa la massima information gain in quanto ogni giorno è un sottoinsieme diverso puro, ma il giorno non determina se le condizione sono buone per andare a giocare.

- Per evitare questo si introduce il GAIN RATIO
    
    Si prende il GainInformation e si divide per lo SplitInformation
    
    $$ GainRatio(S,A)=\frac{Gain(S,A)}{SplitInformation(S,A)} $$
    
    dove SplitInformation(S,A) è dato dato da :
    
    $$ SplitInformation(S,A)=-\sum_{i=1}^{C}\frac {S_i}{S}\log_2(\frac{S_i}{S}) $$
    
    In cui $S_i$ sono gli insiemi ottenuti partizionando. Infatti è la sommatoria delle ripartizioni su C valori della cardinalità di questi sottoinsiemi.
    
    Il gain ratio vuole penalizzare gli attributi che dividono gli esempi in insiemi piccoli mentre se ci sono insiemi con popolazione uguale non li riduce.
    

Ma anche il gain ratio va aggiustato in quanto può essere 0 o comunque molto piccolo quando $|S_i|\simeq|S|$ per alcuni valori di i (Un attributo con il solito valore per tutti gli esempi)

Per mitigare tale effetto va usata la seguente euristica:

1. Calcolare il gain per ogni attributo
2. Considerare il Gain Ratio solo per quelli che hanno un Gain sospetto (in quelli in cui si particellizza il gain diventa alto e quindi è sospetto)

## HP Space Search in DT learning

La ricerca nello spazio delle ipotesi per i DT è come una HILL CLIMBING. mano mano che si crea l’albero è come se si creassero degli alberelli piccoli.

Rispetto al Candidate Elimination :

- lo spazio delle ipotesi è completo (si prendono sia and che or, mentre in Cand. elim. si prendono solo and)
- la ricerca mantiene una singola coretta ipotesi alla volta, mentre C.E. mantiene il version spase che contiene tutte le hp consistenti
- Non si ha back tracking e quindi non si garantisce l’ottimo
- usa tutti gli esempi disponibili e non è incrementale
- può terminare presto accettando classi rumorose
- LA RICERCA NON è COMPLETA

→ Bias induttivo di ricerca: Gli alberi corti sono preferiti a quelli più profondi, ma ciò non è abbastanza. Si devono preferire gli alberi che utilizzano il maggior information gain vicino alla radice.

[Candidate elimination ha bias di linguaggio (tutte le hp consistenti) ma lo spazio delle hp non è completo]

[Ci deve essere BIAS se no si fa overfitting provando tutto lo spazio di ricerca]

Si preferisce bias di ricerca in quanto si vuole essere flessibile senza escludere a priori delle target function sconosciute.

Scegliere uno shorter tree serve per controllare la complessità del modello.

## Estensioni del decision tree

---

Costruire un albero che si adatta troppo agli esempi di training può portare all’over fitting.

Considerato l’errore dell’ipotesi h su un singolo dato di training, $error_D(h)$ [empirico], o sull’intera distribuzione X dei dati, $error_X(h)$ [aspettato]

L’ipotesi h fa over fitting dei dati di training se esiste un altra hp $h'\in H$ tale che :

$$ error_D(h)<error_D(h')\\ error_X(h')<error_X(h) $$

Se si dovesse scartare h’ sapendo solo il primo caso si farebbe errore di over fitting, in quanto h’, anche se si comporta male sui dati di training si comporta meglio sui dati non visti.

→ Come controllare over fitting nei DT: TRAINING AND VALIDATION SET

Si fa smettere di costruire l’albero quando accuratezza inizia a scendere sul validation set, un set diverso al training set

altro approccio : potare l’albero, PRUNING

Ogni nodo è candidato per il pruning, ossia la rimozione del sottoalbero del nodo e tale nodo diventa una foglia e gli viene assegnata la classe più comune. I nodi sono rimossi solo se l’albero risultante non peggiora sul validation set.

Si procede in modo iterativo.

Si deve sacrificare una parte di training.

altro modo: trasformare l’albero in regole e eliminare le regole le cui precondizioni fanno diminuire l’accuratezza nel validation set e poi si riordinano le regole in ordine di accuratezza. Ogni path costruisce una regola diversa e quindi si tagliano i path. Tale metodo è più leggibile all’essere umano.

Per trattare valori continui di attributi A bisognerebbe costruire regole del del tipo $A_c=TRUE \ if \ A<c \ FALSE \ otherwise$

Per determinare c si ordinano gli esempi in accordo ad un attributo e si determinano le soglie in baso al cambio della classe e poi si sceglie quello con il maggior information gain.

Per trattare dati mancanti Si usano altri esempi per indovinare l’attributo. In particolare si usa l’IMPUTATION. Si può:

- sostituire con il più comune
- assegnare una probabilità $p_i$ di ciascun valore $v_i$ in base alle frequenza e assegnare i valori mancanti in accordo alla distribuzione

Quando si hanno attributi con costi diversi si devono fare anche valutazioni sui costi di essi e pesarli nell’albero.

## Geometrical view